{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7d260b",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n",
    "\n",
    "Simple linear regression is a regression technique that models the relationship between a single independent variable and a dependent variable. It assumes a linear relationship between the variables, and the goal is to fit a straight line that best represents the data. For example, we can use simple linear regression to analyze the relationship between the number of hours studied and exam scores.\n",
    "\n",
    "Multiple linear regression, on the other hand, is a regression technique that models the relationship between multiple independent variables and a dependent variable. It extends the concept of simple linear regression by considering multiple predictors. Each predictor has its own coefficient, representing the change in the dependent variable associated with a unit change in the corresponding predictor, while holding other predictors constant. For example, we can use multiple linear regression to analyze the relationship between exam scores and variables such as hours studied, previous GPA, and attendance.\n",
    "\n",
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n",
    "\n",
    "Main assumptions of linear regression:\n",
    "\n",
    "Linearity: The relationship between the independent variables and the dependent variable is linear. You can check this assumption by creating scatter plots and visually inspecting if the data points follow a linear pattern.\n",
    "\n",
    "Independence: The observations are independent of each other. This assumption assumes that there is no correlation between the residuals (the differences between the actual and predicted values). You can check this assumption by examining any potential autocorrelation in the residuals using techniques like Durbin-Watson test or plotting residuals against time or other relevant variables.\n",
    "\n",
    "Homoscedasticity: The variance of the residuals is constant across all levels of the independent variables. You can check this assumption by plotting the residuals against the predicted values or the independent variables and look for any patterns or trends in the spread of residuals.\n",
    "\n",
    "Normality: The residuals are normally distributed. This assumption assumes that the errors follow a normal distribution with mean zero. You can check this assumption by creating a histogram or a QQ plot of the residuals and comparing it to a normal distribution.\n",
    "\n",
    "No multicollinearity: The independent variables are not highly correlated with each other. Multicollinearity can lead to unstable and unreliable estimates of the regression coefficients. You can check for multicollinearity by calculating the correlation matrix between the independent variables and checking for high correlation values (typically above 0.7 or 0.8).\n",
    "\n",
    "To check these assumptions, you can also use statistical tests such as the Jarque-Bera test for normality, the Breusch-Pagan test for homoscedasticity, and variance inflation factor (VIF) for multicollinearity. Additionally, diagnostic plots like residuals vs. fitted values plots and Q-Q plots can provide visual indications of the assumptions.\n",
    " \n",
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.\n",
    "\n",
    " In a linear regression model, the slope represents the change in the dependent variable associated with a one-unit change in the independent variable, while holding other variables constant. It indicates the direction and magnitude of the relationship between the variables. The intercept represents the value of the dependent variable when all independent variables are zero. For example, in a linear regression model predicting house prices based on the area, the slope represents the increase in price per square foot, and the intercept represents the base price when the area is zero .\n",
    " \n",
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "Gradient descent is an optimization algorithm used in machine learning to iteratively update the model parameters in order to minimize the loss function. It calculates the gradient of the loss function with respect to the model parameters and takes steps in the direction of steepest descent to find the optimal parameter values that minimize the loss. It is particularly useful in cases where the number of features or observations is large, as it allows for efficient computation and parameter updates.\n",
    "\n",
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "Multiple linear regression is an extension of simple linear regression that allows for the inclusion of multiple independent variables to model the relationship with a dependent variable. In multiple linear regression, the model equation becomes a linear combination of the predictors, where each predictor is multiplied by its respective coefficient. The goal is still to estimate the coefficients that minimize the difference between the predicted values and the actual values of the dependent variable.\n",
    "\n",
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n",
    "\n",
    "Multicollinearity refers to the presence of high correlation among the independent variables in a multiple linear regression model. It can cause issues in the interpretation of coefficients and can lead to unstable and unreliable results. To detect multicollinearity, we can calculate correlation coefficients among the predictors and examine the variance inflation factor (VIF). If multicollinearity is detected, it can be addressed by removing highly correlated variables, combining variables, or using techniques such as ridge regression or principal component analysis.\n",
    "\n",
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    " Polynomial regression is a regression technique that models the relationship between the independent variable(s) and the dependent variable using polynomial functions of a specified degree. Unlike linear regression, which assumes a linear relationship, polynomial regression can capture non-linear relationships by introducing polynomial terms (e.g., squared or cubed terms) into the regression equation. This allows for more flexibility in fitting the data and capturing complex patterns.\n",
    "\n",
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?\n",
    "\n",
    "The advantages of polynomial regression compared to linear regression include its ability to capture non-linear relationships, flexibility in modeling complex data patterns, and potential for better predictive performance when non-linear relationships exist. However, the disadvantages include the potential for overfitting the data if the polynomial degree is too high, the increased complexity of interpretation due to the presence of higher-degree polynomial terms, and the increased computational complexity. Polynomial regression is preferred when there is a prior expectation or evidence of non-linear relationships between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44cec25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
