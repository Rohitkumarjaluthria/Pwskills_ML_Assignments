{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0e3805",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "\n",
    "Min-Max scaling is a data preprocessing technique used to scale numeric features to a specific range, typically between 0 and 1. It involves subtracting the minimum value from each data point and then dividing it by the range (maximum value minus minimum value). This ensures that the features are transformed to a common scale and preserves the relative relationships between the data points.\n",
    "\n",
    "Example: Suppose we have a dataset of house prices with a range of $100,000 to $1,000,000. By applying Min-Max scaling, we can transform the prices to a range of 0 to 1, making it easier to compare and analyze the data.\n",
    "\n",
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "\n",
    "The Unit Vector technique, also known as normalization, scales the features such that the transformed vector has a length of 1 (unit length). It differs from Min-Max scaling in that it focuses on the direction of the vector rather than its range. It divides each feature by the L2 norm of the vector, which is the square root of the sum of the squares of its elements.\n",
    "\n",
    "Example: Let's consider a dataset of house features, such as area in square feet and number of bedrooms. By applying Unit Vector scaling, we can ensure that each feature's value is divided by the magnitude of the entire feature vector, resulting in a unit-length vector. This normalization technique can be useful when the magnitude of the features is not as important as their direction.\n",
    "\n",
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "\n",
    "PCA (Principal Component Analysis) is a dimensionality reduction technique used to transform a high-dimensional dataset into a lower-dimensional representation. It achieves this by identifying the principal components, which are linear combinations of the original features that capture the most significant variations in the data. The transformed dataset retains as much information as possible while reducing the dimensionality.\n",
    "\n",
    "Example: Suppose we have a dataset with various numerical features, such as age, income, and education level, for individuals. By applying PCA, we can identify the principal components that explain the most variance in the data. This reduced set of components can be used to represent the dataset in a lower-dimensional space while retaining important patterns and reducing computational complexity.\n",
    "\n",
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "PCA can be used for feature extraction by identifying the principal components that best represent the data. These components are a linear combination of the original features and capture the most significant variations in the data. By selecting a subset of the principal components, we can effectively extract the most informative features from the dataset.\n",
    "\n",
    "Example: In a dataset of images, each image can be represented by a large number of pixels as features. Applying PCA can help extract a smaller set of principal components that capture the major patterns in the images, such as edges, textures, or shapes. These principal components can then be used as the new features for further analysis or modeling.\n",
    "\n",
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "\n",
    "In the context of the food delivery recommendation system, Min-Max scaling can be applied to preprocess the price, rating, and delivery time features. By scaling these features to a range between 0 and 1, it ensures that each feature contributes proportionately and allows for easier comparison and analysis. For example, if the price ranges from $5 to $50 and the rating ranges from 1 to 5, Min-Max scaling would transform them to values between 0 and 1, making them directly comparable.\n",
    "\n",
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "\n",
    "In the project involving stock price prediction, PCA can be used to reduce the dimensionality of the dataset containing various financial and market trend features. By applying PCA, we can identify the principal components that capture the major variations in the dataset. These components can represent the most significant patterns in the data, reducing the number of features while retaining most of the information. This dimensionality reduction can help simplify the model and improve its computational efficiency.\n",
    "\n",
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193225a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-0.5789473684210527\n",
      "-0.052631578947368474\n",
      "0.4736842105263157\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "lst= [1, 5, 10, 15, 20]\n",
    "min_value = min(lst)\n",
    "max_value=max(lst)\n",
    "for i in lst:\n",
    "    scaled_value = (i - min_value) * 2 / (max_value - min_value) - 1\n",
    "    print(scaled_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826aacf2",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "The number of principal components to retain in PCA depends on various factors such as the desired dimensionality reduction, the explained variance threshold, and the computational constraints. In practice, it is common to retain enough principal components to capture a significant portion of the variance in the data. A common approach is to set a threshold, such as retaining components that explain 95% or 99% of the variance. The choice of the threshold depends on the specific requirements of the project and the trade-off between dimensionality reduction and information retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39d50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
